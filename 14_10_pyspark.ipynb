{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnnNDf4YF5L7dsQTvNGp35",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DragonMickey/DE_stepik/blob/main/14_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCOwQoiAerCP",
        "outputId": "c4e460d0-0386-4d10-e27d-18f59536f8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip 24.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n"
          ]
        }
      ],
      "source": [
        "pip --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gbl8jnXe8ay",
        "outputId": "cb8dadc6-664e-4dc6-cae8-e8037e7dc3af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=19fe6f84a998bc48235b16a544c9ca18bbd580253560a8217cf06c16e91ad7af\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, year, month\n",
        "# Создание SparkSession\n",
        "spark = SparkSession.builder.appName(\"Task 1. Weather\").getOrCreate()\n",
        "\n",
        "# Чтение CSV-файла\n",
        "df = spark.read.csv(\"weather_data.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Проверка формата данных\n",
        "df.printSchema()\n",
        "\n",
        "# топ-5 самых жарких дней за все время наблюдений.\n",
        "sorted_df1 = df.orderBy(col('temperature').desc()).select(\"date\",\"temperature\").limit(5)\n",
        "sorted_df1.show()\n",
        "\n",
        "# Найдите метеостанцию с наибольшим количеством осадков за последний год.\n",
        "year = df.filter(year(\"date\") == 2023)\n",
        "sorted_df2 = year.groupBy(\"station_id\").sum(\"precipitation\").orderBy(col(\"sum(precipitation)\").desc()).limit(1)\n",
        "sorted_df2.show()\n",
        "\n",
        "# Подсчитайте среднюю температуру по месяцам за все время наблюдений.\n",
        "sorted_df3 = df.withColumn(\"month\", month(\"date\")).groupBy(\"month\").avg(\"temperature\").orderBy(\"month\")\n",
        "sorted_df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jLE9UodG367",
        "outputId": "0ba29ac1-ca6f-4a37-b5f7-50f4903a1be0",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- station_id: string (nullable = true)\n",
            " |-- date: date (nullable = true)\n",
            " |-- temperature: double (nullable = true)\n",
            " |-- precipitation: double (nullable = true)\n",
            " |-- wind_speed: double (nullable = true)\n",
            "\n",
            "+----------+------------------+\n",
            "|      date|       temperature|\n",
            "+----------+------------------+\n",
            "|2021-08-20|39.982828249354846|\n",
            "|2023-12-02| 39.96797489293784|\n",
            "|2022-03-28|  39.8246894248997|\n",
            "|2019-02-11| 39.76737697836647|\n",
            "|2020-06-10| 39.69147838355929|\n",
            "+----------+------------------+\n",
            "\n",
            "+----------+------------------+\n",
            "|station_id|sum(precipitation)|\n",
            "+----------+------------------+\n",
            "| station_5| 642.9302626767898|\n",
            "+----------+------------------+\n",
            "\n",
            "+-----+------------------+\n",
            "|month|  avg(temperature)|\n",
            "+-----+------------------+\n",
            "|    1|11.356518462550754|\n",
            "|    2| 9.067229891101926|\n",
            "|    3| 7.244080205633994|\n",
            "|    4|12.024529009744693|\n",
            "|    5| 9.902883346912718|\n",
            "|    6|13.421092297254138|\n",
            "|    7|6.1857183016954576|\n",
            "|    8|  10.9678002814186|\n",
            "|    9| 9.596744236573942|\n",
            "|   10|  9.09884344821895|\n",
            "|   11| 7.265889994697494|\n",
            "|   12|11.218592100674337|\n",
            "+-----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_date, count, year\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Task 2. Books and authors\").getOrCreate()\n",
        "\n",
        "books_df = spark.read.csv(\"books.csv\", header=True, inferSchema=True)\n",
        "authors_df = spark.read.csv(\"authors.csv\", header=True, inferSchema=True)\n",
        "\n",
        "books_df = books_df.withColumn(\"publish_date\", to_date(\"publish_date\", \"YYYY-MM-DD\"))\n",
        "authors_df = authors_df.withColumn(\"birth_date\", to_date(\"birth_date\", \"yyyy-MM-dd\"))\n",
        "\n",
        "books_authors_df = books_df.join(authors_df, on=\"author_id\", how=\"left\")\n",
        "books_authors_df.show()\n",
        "# Найдите топ-5 авторов, книги которых принесли наибольшую выручку.\n",
        "top_authors = books_authors_df.groupBy(\"name\").sum(\"price\").orderBy(col(\"sum(price)\").desc()).limit(5)\n",
        "top_authors.show()\n",
        "\n",
        "# Найдите количество книг в каждом жанре.\n",
        "count_genre = books_authors_df.groupBy(\"genre\").count().orderBy(col(\"count\").desc())\n",
        "count_genre.show()\n",
        "\n",
        "# Подсчитайте среднюю цену книг по каждому автору.\n",
        "avg_price_author = books_authors_df.groupBy(\"name\").avg(\"price\").orderBy(col(\"avg(price)\").desc())\n",
        "avg_price_author.show()\n",
        "\n",
        "# Найдите книги, опубликованные после 2000 года, и отсортируйте их по цене.\n",
        "books_after_2000 = books_authors_df.filter(year(col(\"publish_date\")) > 2000).orderBy(col(\"price\").desc())\n",
        "books_after_2000.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xsjG2YNo7qVY",
        "outputId": "c88f046c-73b5-4de7-8f0f-a04bac192899"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-------+-----------+-----+------------+---------+----------+---------+\n",
            "|author_id|book_id|  title|      genre|price|publish_date|     name|birth_date|  country|\n",
            "+---------+-------+-------+-----------+-----+------------+---------+----------+---------+\n",
            "|        2|      1| Book_1|    Mystery|73.57|  1980-12-31| Author_2|1965-12-31|   Canada|\n",
            "|        1|      2| Book_2|Non-Fiction| 41.1|  1982-12-31| Author_1|1960-12-31|    India|\n",
            "|       10|      3| Book_3|    Fiction|10.63|  1984-12-31|Author_10|2005-12-31|    India|\n",
            "|        9|      4| Book_4|Non-Fiction|46.31|  1986-12-31| Author_9|2000-12-31|Australia|\n",
            "|        7|      5| Book_5|    Science|31.13|  1988-12-31| Author_7|1990-12-31|      USA|\n",
            "|        4|      6| Book_6|Non-Fiction| 83.7|  1990-12-31| Author_4|1975-12-31|       UK|\n",
            "|        6|      7| Book_7|Non-Fiction|40.36|  1992-12-31| Author_6|1985-12-31|      USA|\n",
            "|        2|      8| Book_8|Non-Fiction|84.48|  1994-12-31| Author_2|1965-12-31|   Canada|\n",
            "|        7|      9| Book_9|    Fantasy|10.05|  1996-12-31| Author_7|1990-12-31|      USA|\n",
            "|        2|     10|Book_10|    Science| 37.7|  1998-12-31| Author_2|1965-12-31|   Canada|\n",
            "|       10|     11|Book_11|Non-Fiction| 31.7|  2000-12-31|Author_10|2005-12-31|    India|\n",
            "|        8|     12|Book_12|Non-Fiction|31.02|  2002-12-31| Author_8|1995-12-31|Australia|\n",
            "|        8|     13|Book_13|Non-Fiction|16.14|  2004-12-31| Author_8|1995-12-31|Australia|\n",
            "|        1|     14|Book_14|    Fiction|26.84|  2006-12-31| Author_1|1960-12-31|    India|\n",
            "|        8|     15|Book_15|    Fantasy| 60.0|  2008-12-31| Author_8|1995-12-31|Australia|\n",
            "|        2|     16|Book_16|    Fiction|36.22|  2010-12-31| Author_2|1965-12-31|   Canada|\n",
            "|        6|     17|Book_17|    Fantasy|47.57|  2012-12-31| Author_6|1985-12-31|      USA|\n",
            "|        1|     18|Book_18|Non-Fiction|43.92|  2014-12-31| Author_1|1960-12-31|    India|\n",
            "|        5|     19|Book_19|    Science|88.83|  2016-12-31| Author_5|1980-12-31|      USA|\n",
            "|        7|     20|Book_20|    Mystery|91.48|  2018-12-31| Author_7|1990-12-31|      USA|\n",
            "+---------+-------+-------+-----------+-----+------------+---------+----------+---------+\n",
            "\n",
            "+--------+----------+\n",
            "|    name|sum(price)|\n",
            "+--------+----------+\n",
            "|Author_2|    231.97|\n",
            "|Author_7|    132.66|\n",
            "|Author_1|    111.86|\n",
            "|Author_8|    107.16|\n",
            "|Author_5|     88.83|\n",
            "+--------+----------+\n",
            "\n",
            "+-----------+-----+\n",
            "|      genre|count|\n",
            "+-----------+-----+\n",
            "|Non-Fiction|    9|\n",
            "|    Science|    3|\n",
            "|    Fiction|    3|\n",
            "|    Fantasy|    3|\n",
            "|    Mystery|    2|\n",
            "+-----------+-----+\n",
            "\n",
            "+---------+-----------------+\n",
            "|     name|       avg(price)|\n",
            "+---------+-----------------+\n",
            "| Author_5|            88.83|\n",
            "| Author_4|             83.7|\n",
            "| Author_2|          57.9925|\n",
            "| Author_9|            46.31|\n",
            "| Author_7|            44.22|\n",
            "| Author_6|           43.965|\n",
            "| Author_1|37.28666666666667|\n",
            "| Author_8|            35.72|\n",
            "|Author_10|           21.165|\n",
            "+---------+-----------------+\n",
            "\n",
            "+---------+-------+-------+-----------+-----+------------+--------+----------+---------+\n",
            "|author_id|book_id|  title|      genre|price|publish_date|    name|birth_date|  country|\n",
            "+---------+-------+-------+-----------+-----+------------+--------+----------+---------+\n",
            "|        7|     20|Book_20|    Mystery|91.48|  2018-12-31|Author_7|1990-12-31|      USA|\n",
            "|        5|     19|Book_19|    Science|88.83|  2016-12-31|Author_5|1980-12-31|      USA|\n",
            "|        8|     15|Book_15|    Fantasy| 60.0|  2008-12-31|Author_8|1995-12-31|Australia|\n",
            "|        6|     17|Book_17|    Fantasy|47.57|  2012-12-31|Author_6|1985-12-31|      USA|\n",
            "|        1|     18|Book_18|Non-Fiction|43.92|  2014-12-31|Author_1|1960-12-31|    India|\n",
            "|        2|     16|Book_16|    Fiction|36.22|  2010-12-31|Author_2|1965-12-31|   Canada|\n",
            "|        8|     12|Book_12|Non-Fiction|31.02|  2002-12-31|Author_8|1995-12-31|Australia|\n",
            "|        1|     14|Book_14|    Fiction|26.84|  2006-12-31|Author_1|1960-12-31|    India|\n",
            "|        8|     13|Book_13|Non-Fiction|16.14|  2004-12-31|Author_8|1995-12-31|Australia|\n",
            "+---------+-------+-------+-----------+-----+------------+--------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Task 3. Movie and actors\").getOrCreate()\n",
        "\n",
        "actors_df = spark.read.csv(\"actors.csv\", header=True, inferSchema=True)\n",
        "movies_df = spark.read.csv(\"movies.csv\", header=True, inferSchema=True)\n",
        "movie_actors_df = spark.read.csv(\"movie_actors.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Регистрация DataFrame как временные таблицы\n",
        "actors_df.createOrReplaceTempView(\"actors\")\n",
        "movies_df.createOrReplaceTempView(\"movies\")\n",
        "movie_actors_df.createOrReplaceTempView(\"movie_actor\")\n",
        "\n",
        "# Найдите топ-5 жанров по количеству фильмов\n",
        "# top_genres = movies_df.groupBy(\"genre\").count().orderBy(col(\"count\").desc()).limit(5)\n",
        "top_genres = spark.sql(\"\"\"\n",
        "SELECT genre, COUNT(*) count\n",
        "FROM movies\n",
        "GROUP BY genre\n",
        "ORDER BY count DESC\n",
        "LIMIT 5\n",
        "\"\"\")\n",
        "top_genres.show()\n",
        "\n",
        "# Найдите актера с наибольшим количеством фильмов.\n",
        "top_actor = spark.sql(\"\"\"\n",
        "SELECT a.name, COUNT(*) count\n",
        "FROM actors a JOIN movie_actor ma USING(actor_id)\n",
        "GROUP BY a.name\n",
        "ORDER BY count DESC\n",
        "LIMIT 1\n",
        "\"\"\")\n",
        "top_actor.show()\n",
        "\n",
        "# Подсчитайте средний бюджет фильмов по жанрам.\n",
        "avg_budget_genre = spark.sql(\"\"\"\n",
        "SELECT genre, AVG(budget) avg_budget\n",
        "FROM movies\n",
        "GROUP BY genre\n",
        "ORDER BY avg_budget DESC\n",
        "\"\"\")\n",
        "avg_budget_genre.show()\n",
        "\n",
        "# Найдите фильмы, в которых снялось более одного актера из одной страны.\n",
        "movies_with_more1_actors_from_country = spark.sql(\"\"\"\n",
        "SELECT m.title, a.country, COUNT(*) count\n",
        "FROM movies m JOIN movie_actor ma USING(movie_id) JOIN actors a USING(actor_id)\n",
        "GROUP BY m.title, a.country\n",
        "HAVING count > 1\n",
        "\"\"\")\n",
        "movies_with_more1_actors_from_country.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmP1c_LXS2aD",
        "outputId": "887fc573-793c-4a8c-8324-10323a5b9897"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "| genre|count|\n",
            "+------+-----+\n",
            "| Drama|    6|\n",
            "|Action|    6|\n",
            "|Comedy|    4|\n",
            "|Horror|    2|\n",
            "|Sci-Fi|    2|\n",
            "+------+-----+\n",
            "\n",
            "+--------+-----+\n",
            "|    name|count|\n",
            "+--------+-----+\n",
            "|Actor_17|    5|\n",
            "+--------+-----+\n",
            "\n",
            "+------+--------------------+\n",
            "| genre|          avg_budget|\n",
            "+------+--------------------+\n",
            "|Horror|      8.7281876775E7|\n",
            "|Sci-Fi|       7.809715175E7|\n",
            "| Drama| 6.076021856166667E7|\n",
            "|Comedy|     5.20709662225E7|\n",
            "|Action|2.7492742561666667E7|\n",
            "+------+--------------------+\n",
            "\n",
            "+--------+---------+-----+\n",
            "|   title|  country|count|\n",
            "+--------+---------+-----+\n",
            "| Movie_7|    India|    2|\n",
            "| Movie_3|      USA|    2|\n",
            "|Movie_10|       UK|    2|\n",
            "|Movie_15|    India|    2|\n",
            "|Movie_18|Australia|    2|\n",
            "| Movie_1|    India|    3|\n",
            "| Movie_2|      USA|    2|\n",
            "| Movie_7|      USA|    2|\n",
            "|Movie_10|      USA|    2|\n",
            "+--------+---------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
